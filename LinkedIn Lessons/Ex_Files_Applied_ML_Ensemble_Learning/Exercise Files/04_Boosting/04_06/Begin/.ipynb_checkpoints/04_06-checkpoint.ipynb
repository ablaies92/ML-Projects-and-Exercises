{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting: Implement a boosting model\n",
    "\n",
    "Using the Titanic dataset from [this](https://www.kaggle.com/c/titanic/overview) Kaggle competition.\n",
    "\n",
    "In this section, we will fit and evaluate a simple Gradient Boosting model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tr_features = pd.read_csv('../../../train_features.csv')\n",
    "tr_labels = pd.read_csv('../../../train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.796 (+/-0.115) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.796 (+/-0.115) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.811 (+/-0.117) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.811 (+/-0.069) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.824 (+/-0.086) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.828 (+/-0.074) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.809 (+/-0.046) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.822 (+/-0.059) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.816 (+/-0.042) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.817 (+/-0.053) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.807 (+/-0.025) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.794 (+/-0.024) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.794 (+/-0.052) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.788 (+/-0.039) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.773 (+/-0.037) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.796 (+/-0.115) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.815 (+/-0.119) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.818 (+/-0.109) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.818 (+/-0.118) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.813 (+/-0.071) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.824 (+/-0.068) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.803 (+/-0.034) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.783 (+/-0.046) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.813 (+/-0.055) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.817 (+/-0.041) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.798 (+/-0.05) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.798 (+/-0.049) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.818 (+/-0.046) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.794 (+/-0.016) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.8 (+/-0.06) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.802 (+/-0.048) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.802 (+/-0.052) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.796 (+/-0.045) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.792 (+/-0.03) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.79 (+/-0.053) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.818 (+/-0.099) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.818 (+/-0.114) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.815 (+/-0.069) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.79 (+/-0.08) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.813 (+/-0.065) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.788 (+/-0.069) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.8 (+/-0.043) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.807 (+/-0.053) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.779 (+/-0.044) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.798 (+/-0.061) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.798 (+/-0.048) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.8 (+/-0.055) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.777 (+/-0.075) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.79 (+/-0.048) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.796 (+/-0.027) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.771 (+/-0.058) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.766 (+/-0.048) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.8 (+/-0.046) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.787 (+/-0.057) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.779 (+/-0.041) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.281 (+/-0.118) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.281 (+/-0.118) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.281 (+/-0.118) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.281 (+/-0.118) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.47 (+/-0.192) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.466 (+/-0.167) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.474 (+/-0.181) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.464 (+/-0.181) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.621 (+/-0.219) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.565 (+/-0.147) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.571 (+/-0.143) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.608 (+/-0.137) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.652 (+/-0.162) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.639 (+/-0.156) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.642 (+/-0.059) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.642 (+/-0.129) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# tr_labels is initially a column of values, but CV wants it to be an array for input; that's where the .values.ravel()\n",
    "# comes into play\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250, 500],\n",
    "    'max_depth': [1, 3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 1, 100]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(gb, parameters, cv = 5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.01, n_estimators=500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this returns the fitted model that returned the best score when applied to the test data\n",
    "# leaving out the max_depth because it is returning 3, which is the defaul\n",
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out pickled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../../models/GB_model.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving model that has been fit on training data; once it is saved, we can leverage it to make predictions on \n",
    "# unseen data\n",
    "joblib.dump(cv.best_estimator_, '../../../models/GB_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
